{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AirFlowPipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPGUElNJPjs7EuTXokNuXlK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PN1019/StockExchanges/blob/main/AirFlowPipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXeiIg1Ps7pc"
      },
      "source": [
        "## Setting Up Stocks_Analysis Pipeline\n",
        " \n",
        "\n",
        "*   Install and configure Airflow\n",
        "\n",
        "\n",
        "*  setup official Apache/Airflow container with PostgreSQL and LocalExecutor using Docker and Docker Compose"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eHjHIxwd8gQ"
      },
      "source": [
        "!mkdir ~/airflow/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWWsnBICfLLy"
      },
      "source": [
        "!mkdir ~/airflow/dags"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRTe_fshnfIc"
      },
      "source": [
        "!mkdir ~/airflow/scripts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rujdoaqaH5Do",
        "outputId": "c88e7b62-b2ba-4b9f-e57c-f60a3d1e672b"
      },
      "source": [
        "!pip install apache-airflow "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting apache-airflow\n",
            "  Downloading apache_airflow-2.1.2-py3-none-any.whl (5.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.2 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cryptography>=0.9.3 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (3.4.7)\n",
            "Collecting openapi-spec-validator>=0.2.4\n",
            "  Downloading openapi_spec_validator-0.3.1-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: importlib-metadata>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (4.6.1)\n",
            "Collecting python-daemon>=2.2.4\n",
            "  Downloading python_daemon-2.3.0-py2.py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: werkzeug>=1.0.1,~=1.0 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (1.0.1)\n",
            "Collecting lazy-object-proxy\n",
            "  Downloading lazy_object_proxy-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.5 MB/s \n",
            "\u001b[?25hCollecting pendulum~=2.0\n",
            "  Downloading pendulum-2.1.2-cp37-cp37m-manylinux1_x86_64.whl (155 kB)\n",
            "\u001b[K     |████████████████████████████████| 155 kB 54.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil<6.0.0,>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (5.4.8)\n",
            "Collecting graphviz>=0.12\n",
            "  Downloading graphviz-0.17-py3-none-any.whl (18 kB)\n",
            "Collecting python-nvd3~=0.15.0\n",
            "  Downloading python-nvd3-0.15.0.tar.gz (31 kB)\n",
            "Requirement already satisfied: pygments<3.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (2.6.1)\n",
            "Collecting apache-airflow-providers-ftp\n",
            "  Downloading apache_airflow_providers_ftp-2.0.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pandas<2.0,>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (1.1.5)\n",
            "Requirement already satisfied: cached-property~=1.5 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (1.5.2)\n",
            "Collecting httpx\n",
            "  Downloading httpx-0.18.2-py3-none-any.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting blinker\n",
            "  Downloading blinker-1.4.tar.gz (111 kB)\n",
            "\u001b[K     |████████████████████████████████| 111 kB 55.1 MB/s \n",
            "\u001b[?25hCollecting marshmallow-oneofschema>=2.0.1\n",
            "  Downloading marshmallow_oneofschema-3.0.1-py2.py3-none-any.whl (5.8 kB)\n",
            "Collecting pyjwt<2\n",
            "  Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: tabulate<0.9,>=0.7.5 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (0.8.9)\n",
            "Collecting clickclick>=1.2\n",
            "  Downloading clickclick-20.10.2-py2.py3-none-any.whl (7.4 kB)\n",
            "Collecting iso8601>=0.1.12\n",
            "  Downloading iso8601-0.1.16-py2.py3-none-any.whl (10 kB)\n",
            "Collecting jsonschema~=3.0\n",
            "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 3.2 MB/s \n",
            "\u001b[?25hCollecting python-slugify<5.0,>=3.0.0\n",
            "  Downloading python-slugify-4.0.1.tar.gz (11 kB)\n",
            "Collecting flask-appbuilder~=3.3\n",
            "  Downloading Flask_AppBuilder-3.3.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 40.1 MB/s \n",
            "\u001b[?25hCollecting colorlog>=4.0.2\n",
            "  Downloading colorlog-5.0.1-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: flask<2.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (1.1.4)\n",
            "Collecting croniter<1.1,>=0.3.17\n",
            "  Downloading croniter-1.0.15-py2.py3-none-any.whl (16 kB)\n",
            "Collecting lockfile>=0.12.2\n",
            "  Downloading lockfile-0.12.2-py2.py3-none-any.whl (13 kB)\n",
            "Collecting flask-caching<2.0.0,>=1.5.0\n",
            "  Downloading Flask_Caching-1.10.1-py3-none-any.whl (34 kB)\n",
            "Collecting apache-airflow-providers-sqlite\n",
            "  Downloading apache_airflow_providers_sqlite-2.0.0-py3-none-any.whl (14 kB)\n",
            "Collecting docutils<0.17\n",
            "  Downloading docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
            "\u001b[K     |████████████████████████████████| 548 kB 54.9 MB/s \n",
            "\u001b[?25hCollecting sqlalchemy-jsonfield~=1.0\n",
            "  Downloading SQLAlchemy_JSONField-1.0.0-py3-none-any.whl (10 kB)\n",
            "Collecting flask-wtf<0.15,>=0.14.3\n",
            "  Downloading Flask_WTF-0.14.3-py2.py3-none-any.whl (13 kB)\n",
            "Collecting setproctitle<2,>=1.1.8\n",
            "  Downloading setproctitle-1.2.2-cp37-cp37m-manylinux1_x86_64.whl (36 kB)\n",
            "Collecting inflection>=0.3.1\n",
            "  Downloading inflection-0.5.1-py2.py3-none-any.whl (9.5 kB)\n",
            "Collecting argcomplete~=1.10\n",
            "  Downloading argcomplete-1.12.3-py2.py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (3.7.4.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (1.1.0)\n",
            "Collecting sqlalchemy<1.4,>=1.3.18\n",
            "  Downloading SQLAlchemy-1.3.24-cp37-cp37m-manylinux2010_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 40.4 MB/s \n",
            "\u001b[?25hCollecting alembic<2.0,>=1.2\n",
            "  Downloading alembic-1.6.5-py2.py3-none-any.whl (164 kB)\n",
            "\u001b[K     |████████████████████████████████| 164 kB 55.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2<2.12.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (2.11.3)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.3 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (2.8.1)\n",
            "Collecting importlib-resources~=1.4\n",
            "  Downloading importlib_resources-1.5.0-py2.py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: dill<0.4,>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (0.3.4)\n",
            "Collecting cattrs<1.7.0,~=1.1\n",
            "  Downloading cattrs-1.5.0-py3-none-any.whl (19 kB)\n",
            "Collecting python3-openid~=3.2\n",
            "  Downloading python3_openid-3.2.0-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 56.3 MB/s \n",
            "\u001b[?25hCollecting swagger-ui-bundle>=0.0.2\n",
            "  Downloading swagger_ui_bundle-0.0.8-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 55.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (1.19.5)\n",
            "Collecting rich>=9.2.0\n",
            "  Downloading rich-10.6.0-py3-none-any.whl (208 kB)\n",
            "\u001b[K     |████████████████████████████████| 208 kB 71.8 MB/s \n",
            "\u001b[?25hCollecting tenacity~=6.2.0\n",
            "  Downloading tenacity-6.2.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting flask-login<0.5,>=0.3\n",
            "  Downloading Flask-Login-0.4.1.tar.gz (14 kB)\n",
            "Collecting gunicorn>=19.5.0\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: markdown<4.0,>=2.5.2 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (3.3.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-airflow) (1.1.0)\n",
            "Collecting unicodecsv>=0.14.1\n",
            "  Downloading unicodecsv-0.14.1.tar.gz (10 kB)\n",
            "Collecting attrs<21.0,>=20.0\n",
            "  Downloading attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 50.0 MB/s \n",
            "\u001b[?25hCollecting apache-airflow-providers-imap\n",
            "  Downloading apache_airflow_providers_imap-2.0.0-py3-none-any.whl (15 kB)\n",
            "Collecting markupsafe<2.0,>=1.1.1\n",
            "  Downloading MarkupSafe-1.1.1-cp37-cp37m-manylinux2010_x86_64.whl (33 kB)\n",
            "Collecting python-editor>=0.3\n",
            "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.4-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from clickclick>=1.2->apache-airflow) (7.1.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=0.9.3->apache-airflow) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=0.9.3->apache-airflow) (2.20)\n",
            "Collecting Flask-Babel<2,>=1\n",
            "  Downloading Flask_Babel-1.0.0-py3-none-any.whl (9.5 kB)\n",
            "Collecting prison<1.0.0,>=0.1.3\n",
            "  Downloading prison-0.1.3-py2.py3-none-any.whl (5.8 kB)\n",
            "Collecting colorama<1,>=0.3.9\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting marshmallow-enum<2,>=1.5.1\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting apispec[yaml]<4,>=3.3\n",
            "  Downloading apispec-3.3.2-py2.py3-none-any.whl (27 kB)\n",
            "Collecting sqlalchemy-utils<1,>=0.32.21\n",
            "  Downloading SQLAlchemy_Utils-0.37.8-py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 9.0 MB/s \n",
            "\u001b[?25hCollecting email-validator<2,>=1.0.5\n",
            "  Downloading email_validator-1.1.3-py2.py3-none-any.whl (18 kB)\n",
            "Collecting Flask-SQLAlchemy<3,>=2.4\n",
            "  Downloading Flask_SQLAlchemy-2.5.1-py2.py3-none-any.whl (17 kB)\n",
            "Collecting marshmallow<4,>=3\n",
            "  Downloading marshmallow-3.13.0-py2.py3-none-any.whl (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 3.6 MB/s \n",
            "\u001b[?25hCollecting Flask-OpenID<2,>=1.2.5\n",
            "  Downloading Flask-OpenID-1.2.5.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting Flask-JWT-Extended<4,>=3.18\n",
            "  Downloading Flask-JWT-Extended-3.25.1.tar.gz (32 kB)\n",
            "Collecting marshmallow-sqlalchemy<0.24.0,>=0.22.0\n",
            "  Downloading marshmallow_sqlalchemy-0.23.1-py2.py3-none-any.whl (18 kB)\n",
            "Collecting dnspython>=1.15.0\n",
            "  Downloading dnspython-2.1.0-py3-none-any.whl (241 kB)\n",
            "\u001b[K     |████████████████████████████████| 241 kB 53.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from email-validator<2,>=1.0.5->flask-appbuilder~=3.3->apache-airflow) (2.10)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from Flask-Babel<2,>=1->flask-appbuilder~=3.3->apache-airflow) (2018.9)\n",
            "Requirement already satisfied: Babel>=2.3 in /usr/local/lib/python3.7/dist-packages (from Flask-Babel<2,>=1->flask-appbuilder~=3.3->apache-airflow) (2.9.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from Flask-JWT-Extended<4,>=3.18->flask-appbuilder~=3.3->apache-airflow) (1.15.0)\n",
            "Collecting WTForms\n",
            "  Downloading WTForms-2.3.3-py2.py3-none-any.whl (169 kB)\n",
            "\u001b[K     |████████████████████████████████| 169 kB 57.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.7/dist-packages (from gunicorn>=19.5.0->apache-airflow) (57.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.7->apache-airflow) (3.5.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema~=3.0->apache-airflow) (0.18.0)\n",
            "Collecting openapi-schema-validator\n",
            "  Downloading openapi_schema_validator-0.1.5-py3-none-any.whl (7.9 kB)\n",
            "Collecting pytzdata>=2020.1\n",
            "  Downloading pytzdata-2020.1-py2.py3-none-any.whl (489 kB)\n",
            "\u001b[K     |████████████████████████████████| 489 kB 65.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify<5.0,>=3.0.0->apache-airflow) (1.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from python3-openid~=3.2->apache-airflow) (0.7.1)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 6.1 MB/s \n",
            "\u001b[?25hCollecting rfc3986[idna2008]<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting httpcore<0.14.0,>=0.13.3\n",
            "  Downloading httpcore-0.13.6-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx->apache-airflow) (2021.5.30)\n",
            "Collecting anyio==3.*\n",
            "  Downloading anyio-3.3.0-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 7.2 MB/s \n",
            "\u001b[?25hCollecting h11<0.13,>=0.11\n",
            "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting isodate\n",
            "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: Flask-JWT-Extended, flask-login, Flask-OpenID, python-nvd3, python-slugify, unicodecsv, blinker\n",
            "  Building wheel for Flask-JWT-Extended (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Flask-JWT-Extended: filename=Flask_JWT_Extended-3.25.1-py2.py3-none-any.whl size=21613 sha256=5c24b14bd7cef8a0618cf05a818258bdc62f2a40e2e4a409bc09ddcac1f10dd3\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/ae/4e/9a2aaa24195ac393559452efb4e82c4dcc3192602886f7a81e\n",
            "  Building wheel for flask-login (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flask-login: filename=Flask_Login-0.4.1-py2.py3-none-any.whl size=15950 sha256=b7789fe1f71c1d4a31b4dd08a41bd112570e16e108f985d262f587cb3146f32c\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/b8/33/1da5a5d39e093a68d81848aa44fd70e3cd0193e6f2d5641052\n",
            "  Building wheel for Flask-OpenID (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Flask-OpenID: filename=Flask_OpenID-1.2.5-py3-none-any.whl size=9134 sha256=3153c664dbfafee378e29961b48f1ca825c21c775d6941fa67861a4e64370c0b\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/7b/bb/26e83746ed4bf0e29b5fdbcfe04a65c1f9b2d007dafebd35a3\n",
            "  Building wheel for python-nvd3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-nvd3: filename=python_nvd3-0.15.0-py3-none-any.whl size=38167 sha256=d0e3877b086149b399b19ce81bc55c38602ccb11512e501b441c0534ae716bf7\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/0e/a4/5290cd4d309d756617f4d8eedd60813653d606e21ccaf7f286\n",
            "  Building wheel for python-slugify (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-slugify: filename=python_slugify-4.0.1-py2.py3-none-any.whl size=6782 sha256=138eda6ef3d7eecfde0313786a3bca74bcd3cdbb54257a253f6832e753102013\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/1b/6f/5c1cfab22eacbe0095fc619786da6571b55253653c71324b5c\n",
            "  Building wheel for unicodecsv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unicodecsv: filename=unicodecsv-0.14.1-py3-none-any.whl size=10767 sha256=2367932c5d8b631f2e9bea9a436b07ba796937cd5451615399f3da149c82b731\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/f4/8a/a5024fb77b32ed369e5c409081e5f00fbe3b92fdad653f6e69\n",
            "  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for blinker: filename=blinker-1.4-py3-none-any.whl size=13479 sha256=8c882456251c4cea658d6a0576b843eba5540cb1b5c1ede32b58ab4450a651e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/f5/18/df711b66eb25b21325c132757d4314db9ac5e8dabeaf196eab\n",
            "Successfully built Flask-JWT-Extended flask-login Flask-OpenID python-nvd3 python-slugify unicodecsv blinker\n",
            "Installing collected packages: markupsafe, sniffio, attrs, WTForms, sqlalchemy, rfc3986, pyyaml, python3-openid, pyjwt, marshmallow, jsonschema, isodate, h11, dnspython, apispec, anyio, sqlalchemy-utils, pytzdata, python-slugify, python-editor, prison, openapi-schema-validator, marshmallow-sqlalchemy, marshmallow-enum, Mako, lockfile, httpcore, flask-wtf, Flask-SQLAlchemy, Flask-OpenID, flask-login, Flask-JWT-Extended, Flask-Babel, email-validator, docutils, commonmark, colorama, unicodecsv, tenacity, swagger-ui-bundle, sqlalchemy-jsonfield, setproctitle, rich, python-nvd3, python-daemon, pendulum, openapi-spec-validator, marshmallow-oneofschema, lazy-object-proxy, iso8601, inflection, importlib-resources, httpx, gunicorn, graphviz, flask-caching, flask-appbuilder, croniter, colorlog, clickclick, cattrs, blinker, argcomplete, apache-airflow-providers-sqlite, apache-airflow-providers-imap, apache-airflow-providers-ftp, alembic, apache-airflow\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 2.0.1\n",
            "    Uninstalling MarkupSafe-2.0.1:\n",
            "      Successfully uninstalled MarkupSafe-2.0.1\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 21.2.0\n",
            "    Uninstalling attrs-21.2.0:\n",
            "      Successfully uninstalled attrs-21.2.0\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 1.4.20\n",
            "    Uninstalling SQLAlchemy-1.4.20:\n",
            "      Successfully uninstalled SQLAlchemy-1.4.20\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 2.6.0\n",
            "    Uninstalling jsonschema-2.6.0:\n",
            "      Successfully uninstalled jsonschema-2.6.0\n",
            "  Attempting uninstall: python-slugify\n",
            "    Found existing installation: python-slugify 5.0.2\n",
            "    Uninstalling python-slugify-5.0.2:\n",
            "      Successfully uninstalled python-slugify-5.0.2\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.17.1\n",
            "    Uninstalling docutils-0.17.1:\n",
            "      Successfully uninstalled docutils-0.17.1\n",
            "  Attempting uninstall: importlib-resources\n",
            "    Found existing installation: importlib-resources 5.2.0\n",
            "    Uninstalling importlib-resources-5.2.0:\n",
            "      Successfully uninstalled importlib-resources-5.2.0\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "nbclient 0.5.3 requires jupyter-client>=6.1.5, but you have jupyter-client 5.3.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed Flask-Babel-1.0.0 Flask-JWT-Extended-3.25.1 Flask-OpenID-1.2.5 Flask-SQLAlchemy-2.5.1 Mako-1.1.4 WTForms-2.3.3 alembic-1.6.5 anyio-3.3.0 apache-airflow-2.1.2 apache-airflow-providers-ftp-2.0.0 apache-airflow-providers-imap-2.0.0 apache-airflow-providers-sqlite-2.0.0 apispec-3.3.2 argcomplete-1.12.3 attrs-20.3.0 blinker-1.4 cattrs-1.5.0 clickclick-20.10.2 colorama-0.4.4 colorlog-5.0.1 commonmark-0.9.1 croniter-1.0.15 dnspython-2.1.0 docutils-0.16 email-validator-1.1.3 flask-appbuilder-3.3.2 flask-caching-1.10.1 flask-login-0.4.1 flask-wtf-0.14.3 graphviz-0.17 gunicorn-20.1.0 h11-0.12.0 httpcore-0.13.6 httpx-0.18.2 importlib-resources-1.5.0 inflection-0.5.1 iso8601-0.1.16 isodate-0.6.0 jsonschema-3.2.0 lazy-object-proxy-1.6.0 lockfile-0.12.2 markupsafe-1.1.1 marshmallow-3.13.0 marshmallow-enum-1.5.1 marshmallow-oneofschema-3.0.1 marshmallow-sqlalchemy-0.23.1 openapi-schema-validator-0.1.5 openapi-spec-validator-0.3.1 pendulum-2.1.2 prison-0.1.3 pyjwt-1.7.1 python-daemon-2.3.0 python-editor-1.0.4 python-nvd3-0.15.0 python-slugify-4.0.1 python3-openid-3.2.0 pytzdata-2020.1 pyyaml-5.4.1 rfc3986-1.5.0 rich-10.6.0 setproctitle-1.2.2 sniffio-1.2.0 sqlalchemy-1.3.24 sqlalchemy-jsonfield-1.0.0 sqlalchemy-utils-0.37.8 swagger-ui-bundle-0.0.8 tenacity-6.2.0 unicodecsv-0.14.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LPShgXwfLG_",
        "outputId": "4c82fd17-610d-4c42-d58d-7d5b874de57c"
      },
      "source": [
        "! airflow db init"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DB: sqlite:////root/airflow/airflow.db\n",
            "[\u001b[34m2021-07-27 11:36:36,496\u001b[0m] {\u001b[34mdb.py:\u001b[0m692} INFO\u001b[0m - Creating tables\u001b[0m\n",
            "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
            "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
            "\u001b[1;33m/usr/local/lib/python3.7/dist-packages/psycopg2/\u001b[0m\u001b[1;33m__init__.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m144\u001b[0m\u001b[1;33m UserWarning\u001b[0m\u001b[33m: The psycopg2 wheel package will be renamed from release \u001b[0m\u001b[1;33m2.8\u001b[0m\u001b[33m; in order to keep installing from binary please use \u001b[0m\u001b[33m\"pip install psycopg2-binary\"\u001b[0m\u001b[33m instead. For details see: \u001b[0m\u001b[1;33m<\u001b[0m\u001b[4;33mhttp:\u001b[0m\u001b[4;33m//initd.org/psycopg/docs/install.html#binary-install-from-pypi\u001b[0m\u001b[1;33m>\u001b[0m\u001b[33m.\u001b[0m\n",
            "INFO  [alembic.runtime.migration] Running upgrade  -> e3a246e0dc1, current schema\n",
            "INFO  [alembic.runtime.migration] Running upgrade e3a246e0dc1 -> 1507a7289a2f, create is_encrypted\n",
            "\u001b[1;33m/usr/local/lib/python3.7/dist-packages/alembic/ddl/\u001b[0m\u001b[1;33msqlite.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m44\u001b[0m\u001b[1;33m UserWarning\u001b[0m\u001b[33m: Skipping unsupported ALTER for creation of implicit constraintPlease refer to the batch mode feature which allows for SQLite migrations using a copy-and-move strategy.\u001b[0m\n",
            "INFO  [alembic.runtime.migration] Running upgrade 1507a7289a2f -> 13eb55f81627, maintain history for compatibility with earlier migrations\n",
            "INFO  [alembic.runtime.migration] Running upgrade 13eb55f81627 -> 338e90f54d61, More logging into task_instance\n",
            "INFO  [alembic.runtime.migration] Running upgrade 338e90f54d61 -> 52d714495f0, job_id indices\n",
            "INFO  [alembic.runtime.migration] Running upgrade 52d714495f0 -> 502898887f84, Adding extra to Log\n",
            "INFO  [alembic.runtime.migration] Running upgrade 502898887f84 -> 1b38cef5b76e, add dagrun\n",
            "INFO  [alembic.runtime.migration] Running upgrade 1b38cef5b76e -> 2e541a1dcfed, task_duration\n",
            "INFO  [alembic.runtime.migration] Running upgrade 2e541a1dcfed -> 40e67319e3a9, dagrun_config\n",
            "INFO  [alembic.runtime.migration] Running upgrade 40e67319e3a9 -> 561833c1c74b, add password column to user\n",
            "INFO  [alembic.runtime.migration] Running upgrade 561833c1c74b -> 4446e08588, dagrun start end\n",
            "INFO  [alembic.runtime.migration] Running upgrade 4446e08588 -> bbc73705a13e, Add notification_sent column to sla_miss\n",
            "INFO  [alembic.runtime.migration] Running upgrade bbc73705a13e -> bba5a7cfc896, Add a column to track the encryption state of the 'Extra' field in connection\n",
            "INFO  [alembic.runtime.migration] Running upgrade bba5a7cfc896 -> 1968acfc09e3, add is_encrypted column to variable table\n",
            "INFO  [alembic.runtime.migration] Running upgrade 1968acfc09e3 -> 2e82aab8ef20, rename user table\n",
            "INFO  [alembic.runtime.migration] Running upgrade 2e82aab8ef20 -> 211e584da130, add TI state index\n",
            "INFO  [alembic.runtime.migration] Running upgrade 211e584da130 -> 64de9cddf6c9, add task fails journal table\n",
            "INFO  [alembic.runtime.migration] Running upgrade 64de9cddf6c9 -> f2ca10b85618, add dag_stats table\n",
            "INFO  [alembic.runtime.migration] Running upgrade f2ca10b85618 -> 4addfa1236f1, Add fractional seconds to mysql tables\n",
            "INFO  [alembic.runtime.migration] Running upgrade 4addfa1236f1 -> 8504051e801b, xcom dag task indices\n",
            "INFO  [alembic.runtime.migration] Running upgrade 8504051e801b -> 5e7d17757c7a, add pid field to TaskInstance\n",
            "INFO  [alembic.runtime.migration] Running upgrade 5e7d17757c7a -> 127d2bf2dfa7, Add dag_id/state index on dag_run table\n",
            "INFO  [alembic.runtime.migration] Running upgrade 127d2bf2dfa7 -> cc1e65623dc7, add max tries column to task instance\n",
            "WARNI [unusual_prefix_569ff5bff83f584bb19ea58703f6c868cf54df8b_example_kubernetes_executor_config] Could not import DAGs in example_kubernetes_executor_config.py: No module named 'kubernetes'\n",
            "WARNI [unusual_prefix_569ff5bff83f584bb19ea58703f6c868cf54df8b_example_kubernetes_executor_config] Install kubernetes dependencies with: pip install apache-airflow['cncf.kubernetes']\n",
            "INFO  [alembic.runtime.migration] Running upgrade cc1e65623dc7 -> bdaa763e6c56, Make xcom value column a large binary\n",
            "INFO  [alembic.runtime.migration] Running upgrade bdaa763e6c56 -> 947454bf1dff, add ti job_id index\n",
            "INFO  [alembic.runtime.migration] Running upgrade 947454bf1dff -> d2ae31099d61, Increase text size for MySQL (not relevant for other DBs' text types)\n",
            "INFO  [alembic.runtime.migration] Running upgrade d2ae31099d61 -> 0e2a74e0fc9f, Add time zone awareness\n",
            "INFO  [alembic.runtime.migration] Running upgrade d2ae31099d61 -> 33ae817a1ff4, kubernetes_resource_checkpointing\n",
            "INFO  [alembic.runtime.migration] Running upgrade 33ae817a1ff4 -> 27c6a30d7c24, kubernetes_resource_checkpointing\n",
            "INFO  [alembic.runtime.migration] Running upgrade 27c6a30d7c24 -> 86770d1215c0, add kubernetes scheduler uniqueness\n",
            "INFO  [alembic.runtime.migration] Running upgrade 86770d1215c0, 0e2a74e0fc9f -> 05f30312d566, merge heads\n",
            "INFO  [alembic.runtime.migration] Running upgrade 05f30312d566 -> f23433877c24, fix mysql not null constraint\n",
            "INFO  [alembic.runtime.migration] Running upgrade f23433877c24 -> 856955da8476, fix sqlite foreign key\n",
            "INFO  [alembic.runtime.migration] Running upgrade 856955da8476 -> 9635ae0956e7, index-faskfail\n",
            "INFO  [alembic.runtime.migration] Running upgrade 9635ae0956e7 -> dd25f486b8ea, add idx_log_dag\n",
            "INFO  [alembic.runtime.migration] Running upgrade dd25f486b8ea -> bf00311e1990, add index to taskinstance\n",
            "INFO  [alembic.runtime.migration] Running upgrade 9635ae0956e7 -> 0a2a5b66e19d, add task_reschedule table\n",
            "INFO  [alembic.runtime.migration] Running upgrade 0a2a5b66e19d, bf00311e1990 -> 03bc53e68815, merge_heads_2\n",
            "INFO  [alembic.runtime.migration] Running upgrade 03bc53e68815 -> 41f5f12752f8, add superuser field\n",
            "INFO  [alembic.runtime.migration] Running upgrade 41f5f12752f8 -> c8ffec048a3b, add fields to dag\n",
            "INFO  [alembic.runtime.migration] Running upgrade c8ffec048a3b -> dd4ecb8fbee3, Add schedule interval to dag\n",
            "INFO  [alembic.runtime.migration] Running upgrade dd4ecb8fbee3 -> 939bb1e647c8, task reschedule fk on cascade delete\n",
            "INFO  [alembic.runtime.migration] Running upgrade 939bb1e647c8 -> 6e96a59344a4, Make TaskInstance.pool not nullable\n",
            "INFO  [alembic.runtime.migration] Running upgrade 6e96a59344a4 -> d38e04c12aa2, add serialized_dag table\n",
            "INFO  [alembic.runtime.migration] Running upgrade d38e04c12aa2 -> b3b105409875, add root_dag_id to DAG\n",
            "INFO  [alembic.runtime.migration] Running upgrade 6e96a59344a4 -> 74effc47d867, change datetime to datetime2(6) on MSSQL tables\n",
            "INFO  [alembic.runtime.migration] Running upgrade 939bb1e647c8 -> 004c1210f153, increase queue name size limit\n",
            "INFO  [alembic.runtime.migration] Running upgrade c8ffec048a3b -> a56c9515abdc, Remove dag_stat table\n",
            "INFO  [alembic.runtime.migration] Running upgrade a56c9515abdc, 004c1210f153, 74effc47d867, b3b105409875 -> 08364691d074, Merge the four heads back together\n",
            "INFO  [alembic.runtime.migration] Running upgrade 08364691d074 -> fe461863935f, increase_length_for_connection_password\n",
            "INFO  [alembic.runtime.migration] Running upgrade fe461863935f -> 7939bcff74ba, Add DagTags table\n",
            "INFO  [alembic.runtime.migration] Running upgrade 7939bcff74ba -> a4c2fd67d16b, add pool_slots field to task_instance\n",
            "INFO  [alembic.runtime.migration] Running upgrade a4c2fd67d16b -> 852ae6c715af, Add RenderedTaskInstanceFields table\n",
            "INFO  [alembic.runtime.migration] Running upgrade 852ae6c715af -> 952da73b5eff, add dag_code table\n",
            "INFO  [alembic.runtime.migration] Running upgrade 952da73b5eff -> a66efa278eea, Add Precision to execution_date in RenderedTaskInstanceFields table\n",
            "INFO  [alembic.runtime.migration] Running upgrade a66efa278eea -> da3f683c3a5a, Add dag_hash Column to serialized_dag table\n",
            "INFO  [alembic.runtime.migration] Running upgrade da3f683c3a5a -> 92c57b58940d, Create FAB Tables\n",
            "INFO  [alembic.runtime.migration] Running upgrade 92c57b58940d -> 03afc6b6f902, Increase length of FAB ab_view_menu.name column\n",
            "INFO  [alembic.runtime.migration] Running upgrade 03afc6b6f902 -> cf5dc11e79ad, drop_user_and_chart\n",
            "INFO  [alembic.runtime.migration] Running upgrade cf5dc11e79ad -> bbf4a7ad0465, Remove id column from xcom\n",
            "INFO  [alembic.runtime.migration] Running upgrade bbf4a7ad0465 -> b25a55525161, Increase length of pool name\n",
            "INFO  [alembic.runtime.migration] Running upgrade b25a55525161 -> 3c20cacc0044, Add DagRun run_type\n",
            "INFO  [alembic.runtime.migration] Running upgrade 3c20cacc0044 -> 8f966b9c467a, Set conn_type as non-nullable\n",
            "INFO  [alembic.runtime.migration] Running upgrade 8f966b9c467a -> 8d48763f6d53, add unique constraint to conn_id\n",
            "INFO  [alembic.runtime.migration] Running upgrade 8d48763f6d53 -> e38be357a868, Add sensor_instance table\n",
            "INFO  [alembic.runtime.migration] Running upgrade e38be357a868 -> b247b1e3d1ed, Add queued by Job ID to TI\n",
            "INFO  [alembic.runtime.migration] Running upgrade b247b1e3d1ed -> e1a11ece99cc, Add external executor ID to TI\n",
            "INFO  [alembic.runtime.migration] Running upgrade e1a11ece99cc -> bef4f3d11e8b, Drop KubeResourceVersion and KubeWorkerId\n",
            "INFO  [alembic.runtime.migration] Running upgrade bef4f3d11e8b -> 98271e7606e2, Add scheduling_decision to DagRun and DAG\n",
            "INFO  [alembic.runtime.migration] Running upgrade 98271e7606e2 -> 52d53670a240, fix_mssql_exec_date_rendered_task_instance_fields_for_MSSQL\n",
            "INFO  [alembic.runtime.migration] Running upgrade 52d53670a240 -> 364159666cbd, Add creating_job_id to DagRun table\n",
            "INFO  [alembic.runtime.migration] Running upgrade 364159666cbd -> 45ba3f1493b9, add-k8s-yaml-to-rendered-templates\n",
            "INFO  [alembic.runtime.migration] Running upgrade 45ba3f1493b9 -> 849da589634d, Prefix DAG permissions.\n",
            "INFO  [alembic.runtime.migration] Running upgrade 849da589634d -> 2c6edca13270, Resource based permissions.\n",
            "[\u001b[34m2021-07-27 11:36:40,109\u001b[0m] {\u001b[34mmanager.py:\u001b[0m788} \u001b[33mWARNING\u001b[0m - \u001b[33mNo user yet created, use flask fab command to do it.\u001b[0m\n",
            "INFO  [alembic.runtime.migration] Running upgrade 2c6edca13270 -> 61ec73d9401f, Add description field to connection\n",
            "INFO  [alembic.runtime.migration] Running upgrade 61ec73d9401f -> 64a7d6477aae, fix description field in connection to be text\n",
            "INFO  [alembic.runtime.migration] Running upgrade 64a7d6477aae -> e959f08ac86c, Change field in DagCode to MEDIUMTEXT for MySql\n",
            "INFO  [alembic.runtime.migration] Running upgrade e959f08ac86c -> 82b7c48c147f, Remove can_read permission on config resource for User and Viewer role\n",
            "[\u001b[34m2021-07-27 11:36:45,003\u001b[0m] {\u001b[34mmanager.py:\u001b[0m788} \u001b[33mWARNING\u001b[0m - \u001b[33mNo user yet created, use flask fab command to do it.\u001b[0m\n",
            "INFO  [alembic.runtime.migration] Running upgrade 82b7c48c147f -> 449b4072c2da, Increase size of connection.extra field to handle multiple RSA keys\n",
            "INFO  [alembic.runtime.migration] Running upgrade 449b4072c2da -> 8646922c8a04, Change default pool_slots to 1\n",
            "INFO  [alembic.runtime.migration] Running upgrade 8646922c8a04 -> 2e42bb497a22, rename last_scheduler_run column\n",
            "INFO  [alembic.runtime.migration] Running upgrade 2e42bb497a22 -> 90d1635d7b86, Increase pool name size in TaskInstance\n",
            "INFO  [alembic.runtime.migration] Running upgrade 90d1635d7b86 -> e165e7455d70, add description field to variable\n",
            "INFO  [alembic.runtime.migration] Running upgrade e165e7455d70 -> a13f7613ad25, Resource based permissions for default FAB views.\n",
            "[\u001b[34m2021-07-27 11:36:46,339\u001b[0m] {\u001b[34mmanager.py:\u001b[0m788} \u001b[33mWARNING\u001b[0m - \u001b[33mNo user yet created, use flask fab command to do it.\u001b[0m\n",
            "WARNI [airflow.models.crypto] empty cryptography key - values will not be stored encrypted.\n",
            "INFO  [airflow.models.dagbag.DagBag] Filling up the DagBag from /root/airflow/dags\n",
            "WARNI [unusual_prefix_569ff5bff83f584bb19ea58703f6c868cf54df8b_example_kubernetes_executor_config] Could not import DAGs in example_kubernetes_executor_config.py: No module named 'kubernetes'\n",
            "WARNI [unusual_prefix_569ff5bff83f584bb19ea58703f6c868cf54df8b_example_kubernetes_executor_config] Install kubernetes dependencies with: pip install apache-airflow['cncf.kubernetes']\n",
            "INFO  [airflow.models.dag] Sync 33 DAGs\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for example_skip_dag\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for example_task_group\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for example_kubernetes_executor\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for example_branch_operator\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for test_utils\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for example_short_circuit_operator\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for example_subdag_operator\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for example_trigger_target_dag\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for tutorial_taskflow_api_etl_virtualenv\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for example_weekday_branch_operator\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for example_xcom_args_with_operators\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for latest_only_with_trigger\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for example_xcom_args\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for example_trigger_controller_dag\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for tutorial_taskflow_api_etl\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for tutorial_etl_dag\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for example_external_task_marker_parent\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for example_nested_branch_dag\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for example_subdag_operator.section-2\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for tutorial\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for example_complex\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for example_subdag_operator.section-1\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for example_task_group_decorator\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for example_python_operator\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for example_bash_operator\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for example_external_task_marker_child\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for example_branch_datetime_operator_2\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for latest_only\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for example_branch_dop_operator_v3\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for example_xcom\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for example_passing_params_via_test_command\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for example_branch_labels\n",
            "INFO  [airflow.models.dag] Creating ORM DAG for example_dag_decorator\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for example_bash_operator to 2021-07-25 00:00:00+00:00\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for example_branch_datetime_operator_2 to 2021-07-25 00:00:00+00:00\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for example_branch_dop_operator_v3 to 2021-07-25 00:00:00+00:00\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for example_branch_labels to 2021-07-25 00:00:00+00:00\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for example_branch_operator to 2021-07-25 00:00:00+00:00\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for example_complex to None\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for example_dag_decorator to None\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for example_external_task_marker_child to None\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for example_external_task_marker_parent to None\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for example_kubernetes_executor to None\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for example_nested_branch_dag to 2021-07-25 00:00:00+00:00\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for example_passing_params_via_test_command to 2021-07-26 00:00:00+00:00\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for example_python_operator to None\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for example_short_circuit_operator to 2021-07-25 00:00:00+00:00\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for example_skip_dag to 2021-07-25 00:00:00+00:00\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for example_subdag_operator to 2021-07-25 00:00:00+00:00\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for example_subdag_operator.section-1 to None\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for example_subdag_operator.section-2 to None\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for example_task_group to 2021-07-25 00:00:00+00:00\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for example_task_group_decorator to 2021-07-25 00:00:00+00:00\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for example_trigger_controller_dag to 2021-07-25 00:00:00+00:00\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for example_trigger_target_dag to None\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for example_weekday_branch_operator to 2021-07-25 00:00:00+00:00\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for example_xcom to 2021-07-25 00:00:00+00:00\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for example_xcom_args to None\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for example_xcom_args_with_operators to None\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for latest_only to 2021-07-25 00:00:00+00:00\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for latest_only_with_trigger to 2021-07-25 00:00:00+00:00\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for test_utils to None\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for tutorial to 2021-07-25 00:00:00+00:00\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for tutorial_etl_dag to None\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for tutorial_taskflow_api_etl to None\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for tutorial_taskflow_api_etl_virtualenv to None\n",
            "INFO  [airflow.models.dag] Sync 2 DAGs\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for example_subdag_operator.section-1 to None\n",
            "INFO  [airflow.models.dag] Setting next_dagrun for example_subdag_operator.section-2 to None\n",
            "Initialization done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrL0Dls5wbHk"
      },
      "source": [
        "***Note : The above command creates 3 files airflow.cfg ,airflow.db and webserver_config.py***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUTosh_YfLDi",
        "outputId": "1c92af97-f4bf-4779-93ec-55bc204bd914"
      },
      "source": [
        "!pip install docker-compose"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting docker-compose\n",
            "  Downloading docker_compose-1.29.2-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▉                             | 10 kB 23.3 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 20 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 30 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 40 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 51 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 61 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 71 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 81 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 92 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 102 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 112 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 114 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting python-dotenv<1,>=0.13.0\n",
            "  Downloading python_dotenv-0.19.0-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: cached-property<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from docker-compose) (1.5.2)\n",
            "Requirement already satisfied: docopt<1,>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from docker-compose) (0.6.2)\n",
            "Requirement already satisfied: PyYAML<6,>=3.10 in /usr/local/lib/python3.7/dist-packages (from docker-compose) (3.13)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from docker-compose) (2.23.0)\n",
            "Collecting texttable<2,>=0.9.0\n",
            "  Downloading texttable-1.6.4-py2.py3-none-any.whl (10 kB)\n",
            "Collecting distro<2,>=1.5.0\n",
            "  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting docker[ssh]>=5\n",
            "  Downloading docker-5.0.0-py2.py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 16.2 MB/s \n",
            "\u001b[?25hCollecting websocket-client<1,>=0.32.0\n",
            "  Downloading websocket_client-0.59.0-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jsonschema<4,>=2.5.1 in /usr/local/lib/python3.7/dist-packages (from docker-compose) (2.6.0)\n",
            "Collecting dockerpty<1,>=0.4.1\n",
            "  Downloading dockerpty-0.4.1.tar.gz (13 kB)\n",
            "Collecting paramiko>=2.4.2\n",
            "  Downloading paramiko-2.7.2-py2.py3-none-any.whl (206 kB)\n",
            "\u001b[K     |████████████████████████████████| 206 kB 17.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from dockerpty<1,>=0.4.1->docker-compose) (1.15.0)\n",
            "Collecting pynacl>=1.0.1\n",
            "  Downloading PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961 kB)\n",
            "\u001b[K     |████████████████████████████████| 961 kB 17.6 MB/s \n",
            "\u001b[?25hCollecting bcrypt>=3.1.3\n",
            "  Downloading bcrypt-3.2.0-cp36-abi3-manylinux2010_x86_64.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.5\n",
            "  Downloading cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 28.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt>=3.1.3->paramiko>=2.4.2->docker[ssh]>=5->docker-compose) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4.2->docker[ssh]>=5->docker-compose) (2.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->docker-compose) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->docker-compose) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->docker-compose) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->docker-compose) (3.0.4)\n",
            "Building wheels for collected packages: dockerpty\n",
            "  Building wheel for dockerpty (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dockerpty: filename=dockerpty-0.4.1-py3-none-any.whl size=16615 sha256=6cfd9cf8442d7e7d6f1314540308cfd1f208c5f061c742195265dec80d03ffc3\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/40/ea/b275182c42dc7be184c36518d42999bc5267268af2639e409b\n",
            "Successfully built dockerpty\n",
            "Installing collected packages: websocket-client, pynacl, cryptography, bcrypt, paramiko, docker, texttable, python-dotenv, dockerpty, distro, docker-compose\n",
            "Successfully installed bcrypt-3.2.0 cryptography-3.4.7 distro-1.5.0 docker-5.0.0 docker-compose-1.29.2 dockerpty-0.4.1 paramiko-2.7.2 pynacl-1.4.0 python-dotenv-0.19.0 texttable-1.6.4 websocket-client-0.59.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4raUFqdH5H5",
        "outputId": "e3c314f8-b484-46df-bf03-290ad540d12f"
      },
      "source": [
        "!pip install yfinance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.63.tar.gz (26 kB)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.23.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.9)\n",
            "Collecting lxml>=4.5.1\n",
            "  Downloading lxml-4.6.3-cp37-cp37m-manylinux2014_x86_64.whl (6.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 6.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n",
            "Building wheels for collected packages: yfinance\n",
            "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yfinance: filename=yfinance-0.1.63-py2.py3-none-any.whl size=23919 sha256=c1715b13d136efeb2d6c5f183b6a8a2f0101f87c30d8f78c04cca07b21ee4fe8\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/87/8b/7ec24486e001d3926537f5f7801f57a74d181be25b11157983\n",
            "Successfully built yfinance\n",
            "Installing collected packages: lxml, yfinance\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "Successfully installed lxml-4.6.3 yfinance-0.1.63\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w96_i_xExMu5"
      },
      "source": [
        "#entrypoint.sh\n",
        "with open('/root/airflow/scripts/entrypoint.sh', 'w') as writefile:\n",
        "    writefile.writelines(\"#entrypoint.sh\\n\")\n",
        "    writefile.writelines(\" airflow initdb\\n\")\n",
        "    writefile.writelines(\"airflow webserver\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JPbWo9N3ksk",
        "outputId": "b9fd1a8b-6920-4116-8d9b-4f37db402835"
      },
      "source": [
        "with open('/root/airflow/scripts/entrypoint.sh', 'r') as testwritefile:\n",
        "    print(testwritefile.read())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#entrypoint.sh\n",
            " airflow initdb\n",
            "airflow webserver\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUDXYOBrz8eY"
      },
      "source": [
        "with open('/root/airflow/postgres_db.env', 'w') as writefile:\n",
        "    writefile.writelines(\"#postgres_db.env\\n\")\n",
        "    writefile.writelines(\"AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow\\n\")\n",
        "    writefile.writelines(\"AIRFLOW__CORE__EXECUTOR=LocalExecutor\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwyLmSwN4D51",
        "outputId": "c2651976-78c2-4626-a067-30e80a5eb7e5"
      },
      "source": [
        "with open('/root/airflow/postgres_db.env', 'r') as testwritefile:\n",
        "    print(testwritefile.read())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#postgres_db.env\n",
            "AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow\n",
            "AIRFLOW__CORE__EXECUTOR=LocalExecutor\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFKG88u6xMxW"
      },
      "source": [
        "with open('/root/airflow/docker-compose.yml', 'w') as writefile:\n",
        "    writefile.write(\"#docker-compose.yml\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAwAF11l4D32",
        "outputId": "3cb3934b-e5d4-4b3e-c551-13ceb79a676c"
      },
      "source": [
        "with open('/root/airflow/docker-compose.yml', 'r') as testwritefile:\n",
        "    print(testwritefile.read())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#docker-compose.yml\n",
            "version: '3.8'\n",
            "services:\n",
            "    postgres:\n",
            "        image: postgres\n",
            "        environment:\n",
            "            - POSTGRES_USER=airflow\n",
            "            - POSTGRES_PASSWORD=airflow\n",
            "            - POSTGRES_DB=airflow\n",
            "    scheduler:\n",
            "        image: apache/airflow\n",
            "        command: scheduler\n",
            "        depends_on:\n",
            "            - postgres\n",
            "        env_file:\n",
            "            - postgres_db.env\n",
            "        volumes:\n",
            "            - ./dags:/opt/airflow/dags\n",
            "            - ./logs:/opt/airflow/logs\n",
            "    webserver:\n",
            "        image: apache/airflow\n",
            "        entrypoint: ./scripts/entrypoint.sh\n",
            "        \n",
            "        depends_on:\n",
            "            - postgres\n",
            "            - scheduler\n",
            "        env_file:\n",
            "            - postgres_db.env\n",
            "        volumes:\n",
            "            - ./dags:/opt/airflow/dags\n",
            "            - ./logs:/opt/airflow/logs\n",
            "            - ./scripts:/opt/airflow/scripts\n",
            "        ports:\n",
            "            - \"8080:8080\"\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1BVaPM67UYx"
      },
      "source": [
        "#dummy_dag.py\n",
        "with open('/root/airflow/dags/dummy_dag.py', 'w') as writefile:\n",
        "    writefile.write(\"#dummy_dag.py\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4d0_CyM_s9w",
        "outputId": "af221591-04a6-4b28-f80c-9f626f0f28d6"
      },
      "source": [
        "with open('/root/airflow/dags/dummy_dag.py', 'r') as testwritefile:\n",
        "    print(testwritefile.read())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#dummy_dag.py\n",
            "from airflow import DAG\n",
            "from airflow.operators.dummy_operator import DummyOperator\n",
            "from datetime import datetime\n",
            "with DAG('example_dag', start_date=datetime(2021, 7, 27)) as dag:\n",
            "    op = DummyOperator(task_id='op')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Q_3GcHLKIQ2",
        "outputId": "ddf918f7-75f4-4402-8260-5d2cbadfed4b"
      },
      "source": [
        "!pwd\n",
        "import os\n",
        "os.chdir('/root/airflow/')\n",
        "!pwd\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/airflow\n",
            "/root/airflow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCeNAY60H8Yz",
        "outputId": "c58783b2-9710-441f-f681-af3bedc63c36"
      },
      "source": [
        "!docker-compose up"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\", line 600, in urlopen\n",
            "    chunked=chunked)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\", line 354, in _make_request\n",
            "    conn.request(method, url, **httplib_request_kw)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1281, in request\n",
            "    self._send_request(method, url, body, headers, encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1327, in _send_request\n",
            "    self.endheaders(body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1276, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1036, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 976, in send\n",
            "    self.connect()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/docker/transport/unixconn.py\", line 43, in connect\n",
            "    sock.connect(self.unix_socket)\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/adapters.py\", line 449, in send\n",
            "    timeout=timeout\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\", line 638, in urlopen\n",
            "    _stacktrace=sys.exc_info()[2])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/util/retry.py\", line 368, in increment\n",
            "    raise six.reraise(type(error), error, _stacktrace)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/packages/six.py\", line 685, in reraise\n",
            "    raise value.with_traceback(tb)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\", line 600, in urlopen\n",
            "    chunked=chunked)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\", line 354, in _make_request\n",
            "    conn.request(method, url, **httplib_request_kw)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1281, in request\n",
            "    self._send_request(method, url, body, headers, encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1327, in _send_request\n",
            "    self.endheaders(body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1276, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 1036, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 976, in send\n",
            "    self.connect()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/docker/transport/unixconn.py\", line 43, in connect\n",
            "    sock.connect(self.unix_socket)\n",
            "urllib3.exceptions.ProtocolError: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory'))\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/docker/api/client.py\", line 214, in _retrieve_server_version\n",
            "    return self.version(api_version=False)[\"ApiVersion\"]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/docker/api/daemon.py\", line 181, in version\n",
            "    return self._result(self._get(url), json=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/docker/utils/decorators.py\", line 46, in inner\n",
            "    return f(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/docker/api/client.py\", line 237, in _get\n",
            "    return self.get(url, **self._set_request_timeout(kwargs))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/sessions.py\", line 543, in get\n",
            "    return self.request('GET', url, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/sessions.py\", line 530, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/sessions.py\", line 643, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/requests/adapters.py\", line 498, in send\n",
            "    raise ConnectionError(err, request=request)\n",
            "requests.exceptions.ConnectionError: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory'))\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/docker-compose\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/compose/cli/main.py\", line 81, in main\n",
            "    command_func()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/compose/cli/main.py\", line 200, in perform_command\n",
            "    project = project_from_options('.', options)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/compose/cli/command.py\", line 70, in project_from_options\n",
            "    enabled_profiles=get_profiles_from_options(options, environment)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/compose/cli/command.py\", line 153, in get_project\n",
            "    verbose=verbose, version=api_version, context=context, environment=environment\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/compose/cli/docker_client.py\", line 43, in get_client\n",
            "    environment=environment, tls_version=get_tls_version(environment)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/compose/cli/docker_client.py\", line 170, in docker_client\n",
            "    client = APIClient(use_ssh_client=not use_paramiko_ssh, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/docker/api/client.py\", line 197, in __init__\n",
            "    self._version = self._retrieve_server_version()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/docker/api/client.py\", line 222, in _retrieve_server_version\n",
            "    'Error while fetching server API version: {0}'.format(e)\n",
            "docker.errors.DockerException: Error while fetching server API version: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory'))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "halF7y0PDQ0f",
        "outputId": "e63beafe-abb3-4baf-be8f-3db9399470ee"
      },
      "source": [
        "! airflow webserver -p 8080"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;33m/usr/local/lib/python3.7/dist-packages/psycopg2/\u001b[0m\u001b[1;33m__init__.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m144\u001b[0m\u001b[1;33m UserWarning\u001b[0m\u001b[33m: The psycopg2 wheel package will be renamed from release \u001b[0m\u001b[1;33m2.8\u001b[0m\u001b[33m; in order to keep installing from binary please use \u001b[0m\u001b[33m\"pip install psycopg2-binary\"\u001b[0m\u001b[33m instead. For details see: \u001b[0m\u001b[1;33m<\u001b[0m\u001b[4;33mhttp:\u001b[0m\u001b[4;33m//initd.org/psycopg/docs/install.html#binary-install-from-pypi\u001b[0m\u001b[1;33m>\u001b[0m\u001b[33m.\u001b[0m\n",
            "  ____________       _____________\n",
            " ____    |__( )_________  __/__  /________      __\n",
            "____  /| |_  /__  ___/_  /_ __  /_  __ \\_ | /| / /\n",
            "___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /\n",
            " _/_/  |_/_/  /_/    /_/    /_/  \\____/____/|__/\n",
            "[\u001b[34m2021-07-27 13:06:50,827\u001b[0m] {\u001b[34mdagbag.py:\u001b[0m496} INFO\u001b[0m - Filling up the DagBag from \u001b[01m/dev/null\u001b[22m\u001b[0m\n",
            "[\u001b[34m2021-07-27 13:06:50,879\u001b[0m] {\u001b[34mmanager.py:\u001b[0m788} \u001b[33mWARNING\u001b[0m - \u001b[33mNo user yet created, use flask fab command to do it.\u001b[0m\n",
            "Running the Gunicorn Server with:\n",
            "Workers: 4 sync\n",
            "Host: 0.0.0.0:8080\n",
            "Timeout: 120\n",
            "Logfiles: - -\n",
            "Access Logformat: \n",
            "=================================================================            \n",
            "[2021-07-27 13:06:53 +0000] [773] [INFO] Starting gunicorn 20.1.0\n",
            "[2021-07-27 13:06:53 +0000] [773] [ERROR] Connection in use: ('0.0.0.0', 8080)\n",
            "[2021-07-27 13:06:53 +0000] [773] [ERROR] Retrying in 1 second.\n",
            "[2021-07-27 13:06:54 +0000] [773] [ERROR] Connection in use: ('0.0.0.0', 8080)\n",
            "[2021-07-27 13:06:54 +0000] [773] [ERROR] Retrying in 1 second.\n",
            "[2021-07-27 13:06:55 +0000] [773] [ERROR] Connection in use: ('0.0.0.0', 8080)\n",
            "[2021-07-27 13:06:55 +0000] [773] [ERROR] Retrying in 1 second.\n",
            "[2021-07-27 13:06:56 +0000] [773] [ERROR] Connection in use: ('0.0.0.0', 8080)\n",
            "[2021-07-27 13:06:56 +0000] [773] [ERROR] Retrying in 1 second.\n",
            "[2021-07-27 13:06:57 +0000] [773] [ERROR] Connection in use: ('0.0.0.0', 8080)\n",
            "[2021-07-27 13:06:57 +0000] [773] [ERROR] Retrying in 1 second.\n",
            "[2021-07-27 13:06:58 +0000] [773] [ERROR] Can't connect to ('0.0.0.0', 8080)\n",
            "[\u001b[34m2021-07-27 13:08:52,857\u001b[0m] {\u001b[34mwebserver_command.py:\u001b[0m217} \u001b[31mERROR\u001b[0m - \u001b[31mNo response from gunicorn master within 120 seconds\u001b[0m\n",
            "[\u001b[34m2021-07-27 13:08:52,858\u001b[0m] {\u001b[34mwebserver_command.py:\u001b[0m218} \u001b[31mERROR\u001b[0m - \u001b[31mShutting down webserver\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k52qMC7Cg_bW"
      },
      "source": [
        "**Note: It's possible to run Docker in Colab, but with limiting functionality. There are two methods of running Docker service, a regular one (more restrictive), and in rootless mode ( dockerd inside RootlessKit).**\n",
        "\n",
        "One more thing we need a permanent directory structure for docker containers so no use in creating the directory with google collab directory and file commands making a useless overload of tasks on developer for pipeline setup for every single time. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LftypYLzpHYN"
      },
      "source": [
        "**Note:Also, You can run the airflow web server on colab but the problem is that you cannot run scheduler as this webserver keeps on running.\n",
        "Ideally you would open a new shell and run scheduler which opens the airflow web UI but in this case I am not sure how to open a new shell (or a new notebook that has a connected runtime) on colab.**\n",
        "\n",
        "So, We will no longer set up it with Google Collab so it doesn't affect the prospects of the project pipeline."
      ]
    }
  ]
}